{"path":"attachments/Deep Reinforcement Learning-15.png","text":"MIT 6.S091: Introduction to Deep Reinforcement Learning (Deep RL ° ~» DQN Tricks * Experience Replay * Stores experiences (actions, state transitions, and rewards) and creates mini-batches from them for the training process * Fixed Target Network * Error calculation includes the target function depends on network e K parameters and thus changes quickly. Updating it only every 1,000 | < e N\\ steps increases stability of training process. Q(slva) o Q(s?va) + [TI~| \" 5 7“1;1x Q(slélvp) (I Q(st?u)] ‘ Replay x x Target X X Breakout 316.8 240.7 10.2 3.2 River Raid 7446.6 4102.8 2867.7 1453.0 Seaquest 2894.4 822.6 1003.0 275.8 Space Invaders 1088.9 826.3 373.2 302.0 . @ e o","libVersion":"0.3.2","langs":"eng"}