{"path":"attachments/Computer Vision-44.png","text":":__’° S (QHBLLS LS Of « AlexNet (2012): First CNN (15.4%) o » ——1 + 8layers = - < * 61 million parameters 8§ 5 « ZFNet (2013): 15.4% to 11.2% “‘_3_“ = :i ) * More filters. Denser stride. =3 SIa = « VGGNet (2014): 11.2% to 7.3% —— ‘ M / ] i (1 /‘ f B i ‘1\\,\\),,.7 = === e ) * Beautifully uniform: T 4, : - :—' put 3x3 convy, stride 1, pad 1, 2x2 max pool a ™ = - : = f' ~ * 16 layers it b : g s Y * 138 million parameters ' = = ) * GoogleNet (2014): 11.2% to 6.7% = - st - ,_\" . = — [E—— oy ) * Inception modules J‘ : . :—' ;\\\" * 22 layers ' + + M - 2 ,: 7* 4 * 5 million parameters Rpl :gg\\\\' 2 'i . (throw away fully connected layers) S == 132%/) 1 « ResNet (2015): 6.7% to 3.57% = =F ~ o St * More layers = better performance = * 152 layers * CUImage (2016): 3.57% to 2.99% He, Kaiming, et al. \"Deep residual learning for image recognition.\" Proceedings * Ensemble of 6 models Lg< of the IEEE Conference on Computer Vision and Pattern Recognition. 2016. supscaibe P","libVersion":"0.3.2","langs":"eng"}