{"path":"attachments/Deep Reinforcement Learning-29.png","text":"AlphaGo Zero Approach * Same as the best before: Monte Carlo Tree Search (MCTS) » Balance exploitation/exploration (going deep on promising positions or exploring new underplayed positions) * Use a neural network as “intuition” for which positions to expand as part of MCTS (same as AlphaGo) a Selection b Expansion c Evaluation d Backup ] 1 £ 1 max Q+u(P) LAt N Lo \\ Y % 1% B B ¥ £2: ¢ Q + u(P) /nax ‘ : e 154 ’/ Sy 47 p.(F¢T) |?4 (—\"L) Ty T h N ! i 3 i ($5%) 3¢) () (88 I ™ [170] https://deeplearning.mit.edu 2019","libVersion":"0.3.2","langs":"eng"}