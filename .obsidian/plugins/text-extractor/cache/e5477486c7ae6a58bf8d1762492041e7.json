{"path":"attachments/Computer Vision-39.png","text":"* AlexNet (2012): First CNN (15.4%) 03 * 8layers * 61 million parameters 0.25 e, = * ZFNet (2013): 15.4% to 11.2% g 0.2 * 8 layers w c * More filters. Denser stride. O s ‘5 * VGGNet (2014): 11.2% to 7.3% E s « Beautifully uniform: v o 16'7%+ 23’3%“1’ 3x3 cony, stride 1, pad 1, 2x2 max pool B 2V — ) R (VXE A (= ‘ : e Z B B | O 005 * 16 layers 1 ) / 0 0.023 * 138 million parameters i o | 2010 2011 2012 2013 2014 2015 2016 2017 + GoogleNet (2014): 11.2% to 6.7% O | * Inception modules 4 * 22 layers ‘ * 5 million parameters _— = ‘_‘ (throw away fully connected layers) . 0 . i Human error. 51/;, * ResNet (2015): 6.7% to 3.57% | * More layers = better performance P .\"‘\" * Surpassed in 2015 . 152 layers = * CUlmage (2016): 3.57% to 2.99% * Ensemble of 6 models * SENet (2017): 2.99% to 2.251% * Squeeze and excitation block: network is allowed to adaptively adjust the weighting of each feature map in the convolutional block. Lg( H ‘\\j'l\"_z . ‘ References: [90] MIT 6.5094: Deep Learning for Self-Driving Cars Lex Fridman January cone","libVersion":"0.3.2","langs":"eng"}